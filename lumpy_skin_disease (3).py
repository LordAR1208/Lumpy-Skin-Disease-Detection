# -*- coding: utf-8 -*-
"""Lumpy Skin Disease.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YigfYDTIkvNgSso3anntI3rlx5xyS3H7
"""

!pip install ipython --upgrade

!pip install jedi>=0.16

!pip install tpot==0.12.2

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import classification_report, roc_auc_score
from imblearn.over_sampling import SMOTE
from tpot import TPOTClassifier

# Load dataset
file_path = 'Lumpy skin disease data.csv'
data = pd.read_csv(file_path)

data = data.drop(['region', 'country', 'reportingDate'], axis=1)

data = data.dropna()

X = data.drop('lumpy', axis=1)
y = data['lumpy']

y = LabelEncoder().fit_transform(y)

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X_scaled, y)

X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.3, random_state=42, stratify=y_resampled)

numeric_df = data.select_dtypes(include=['number'])

corr_matrix = numeric_df.corr()
# Plot the heatmap
plt.figure(figsize=(10, 8))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)
plt.title('Correlation Matrix Heatmap')
plt.show()

sns.countplot(x=y_resampled)
plt.title('Distribution of Target Variable (Lumpy) After SMOTE')
plt.show()

"""TPOT"""

tpot = TPOTClassifier(generations=1, population_size=50, cv=5, random_state=42, verbosity=2)

# Fit TPOTClassifier
tpot.fit(X_train, y_train)
best_pipeline = tpot.fitted_pipeline_

# Evaluate performance
print("Best pipeline:", best_pipeline)

y_pred = best_pipeline.predict(X_test)
roc_score = roc_auc_score(y_test, best_pipeline.predict_proba(X_test)[:, 1])
print("Classification Report:\n", classification_report(y_test, y_pred))
print("ROC AUC Score:", roc_score)

"""TPOT with Stratified KFold"""

from sklearn.model_selection import StratifiedKFold, cross_val_score

# Extract the best pipeline from TPOT (already fitted)
best_pipeline = tpot.fitted_pipeline_

# Initialize Stratified K-Fold cross-validation
skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

# Perform Stratified K-Fold cross-validation
skf_scores = cross_val_score(best_pipeline, X_train, y_train, cv=skf, scoring='accuracy')

# Output results
print("Stratified K-Fold Cross Validation Scores: ", skf_scores)
print("Mean Stratified K-Fold Score: ", skf_scores.mean())

"""TPOT with KFold"""

from sklearn.model_selection import KFold, cross_val_score

# Extract the best pipeline from TPOT (already fitted)
best_pipeline = tpot.fitted_pipeline_

# Initialize K-Fold Cross Validation (e.g., 5 folds)
kf = KFold(n_splits=5, shuffle=True, random_state=42)

# Perform K-Fold CV on the best pipeline
kf_scores = cross_val_score(best_pipeline, X_train, y_train, cv=kf, scoring='accuracy')

# Output results
print("K-Fold Cross Validation Scores: ", kf_scores)
print("Mean K-Fold CV Score: ", kf_scores.mean())

!pip install lime

from lime import lime_tabular

# Convert X_test to a Pandas DataFrame for using .iloc
X_test_df = pd.DataFrame(X_test, columns=X.columns)

# Create a LimeTabularExplainer instance
explainer = lime_tabular.LimeTabularExplainer(
    training_data=X_train,  # Or X if using original data
    feature_names=X.columns,
    class_names=['0', '1'], # Assuming binary classification
    mode='classification'
)

# Now you can use .iloc
exp = explainer.explain_instance(X_test_df.iloc[0], best_pipeline.predict_proba)
exp.show_in_notebook()

import matplotlib.pyplot as plt
import seaborn as sns

# Data from the image
features = ["X5_Ct_2010_Da", "y", "dominant_land_cover", "pre", "elevation",
            "X5_Bf_2010_Da", "x", "tmp", "dtr", "vap"]
values = [-0.28, -0.59, 1.05, 0.61, 2.17, -0.90, -0.76, -1.48, -0.15, 0.25]

# Set figure size
plt.figure(figsize=(8, 5))

# Color based on value: Orange for negative, Blue for positive
colors = ["orange" if v < 0 else "blue" for v in values]

# Create bar plot
sns.barplot(x=values, y=features, palette=colors)

# Add labels and title
plt.xlabel("Feature Contribution")
plt.ylabel("Feature Name")
plt.title("LIME Feature Importance (Instance-Based)")

# Add vertical reference line at zero
plt.axvline(0, color="black", linewidth=1)

# Show plot
plt.show()

from sklearn.metrics import accuracy_score, log_loss, confusion_matrix, roc_curve, auc
y_train_pred = best_pipeline.predict(X_train)
y_test_pred = best_pipeline.predict(X_test)

# Get predicted probabilities for ROC curve
y_test_proba = best_pipeline.predict_proba(X_test)[:, 1] if hasattr(best_pipeline, "predict_proba") else None

# Compute accuracy and log loss
train_accuracy = accuracy_score(y_train, y_train_pred)
test_accuracy = accuracy_score(y_test, y_test_pred)

train_loss = log_loss(y_train, best_pipeline.predict_proba(X_train)) if hasattr(best_pipeline, "predict_proba") else None
test_loss = log_loss(y_test, best_pipeline.predict_proba(X_test)) if hasattr(best_pipeline, "predict_proba") else None

plt.figure(figsize=(6, 5))
cm = confusion_matrix(y_test, y_test_pred)
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues")
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.title("Confusion Matrix")
plt.show()

if y_test_proba is not None:
    fpr, tpr, _ = roc_curve(y_test, y_test_proba)
    roc_auc = auc(fpr, tpr)

    plt.figure(figsize=(6, 5))
    plt.plot(fpr, tpr, color="blue", lw=2, label=f"ROC curve (area = {roc_auc:.2f})")
    plt.plot([0, 1], [0, 1], color="gray", linestyle="--")
    plt.xlabel("False Positive Rate")
    plt.ylabel("True Positive Rate")
    plt.title("ROC Curve")
    plt.legend(loc="lower right")
    plt.show()

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping

model = Sequential()
model.add(Dense(64, activation='relu', input_shape=(X_train.shape[1],)))
model.add(Dropout(0.3))
model.add(Dense(32, activation='relu'))
model.add(Dropout(0.3))
model.add(Dense(1, activation='sigmoid'))

# Compile the model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Early stopping
early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)

# Train the model
history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.3, callbacks=[early_stopping], verbose=1)

# Evaluate the model
eval_results = model.evaluate(X_test, y_test, verbose=0)
y_pred = (model.predict(X_test) > 0.5).astype(int).flatten()
roc_score = roc_auc_score(y_test, model.predict(X_test))

# Print performance metrics
print("Test Loss:", eval_results[0])
print("Test Accuracy:", eval_results[1])
print("Classification Report:\n", classification_report(y_test, y_pred))
print("ROC AUC Score:", roc_score)

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, LSTM, Embedding
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.preprocessing.sequence import pad_sequences

# Reshape X_train to be 3-dimensional
X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)
X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)

# LSTM Classifier
# Build the model
model = Sequential()
model.add(LSTM(64, activation='tanh', input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True)) # Now X_train.shape[2] will exist
model.add(Dropout(0.2))
model.add(LSTM(32, activation='tanh', return_sequences=False))
model.add(Dropout(0.2))
model.add(Dense(1, activation='sigmoid'))

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Early stopping
early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)

# Train the model
history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.3, callbacks=[early_stopping], verbose=1)

# Evaluate the model
eval_results = model.evaluate(X_test, y_test, verbose=0)
y_pred = (model.predict(X_test) > 0.5).astype(int).flatten()
roc_score = roc_auc_score(y_test, model.predict(X_test))

print("Test Loss:", eval_results[0])
print("Test Accuracy:", eval_results[1])
print("Classification Report:\n", classification_report(y_test, y_pred))
print("ROC AUC Score:", roc_score)

from tensorflow.keras.layers import Dense, Dropout, LSTM, Bidirectional

model = Sequential()
model.add(Bidirectional(LSTM(64, activation='tanh', return_sequences=True), input_shape=(X_train.shape[1], X_train.shape[2])))
model.add(Dropout(0.2))
model.add(Bidirectional(LSTM(32, activation='tanh', return_sequences=False)))
model.add(Dropout(0.2))
model.add(Dense(1, activation='sigmoid'))

# Compile the model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Early stopping
early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)
history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.3, callbacks=[early_stopping], verbose=1)

eval_results = model.evaluate(X_test, y_test, verbose=0)
y_pred = (model.predict(X_test) > 0.5).astype(int).flatten()
roc_score = roc_auc_score(y_test, model.predict(X_test))

# Print performance metrics
print("Test Loss:", eval_results[0])
print("Test Accuracy:", eval_results[1])
print("Classification Report:\n", classification_report(y_test, y_pred))
print("ROC AUC Score:", roc_score)

from tensorflow.keras.layers import Dense, Dropout, GRU

model = Sequential()
model.add(GRU(64, activation='tanh', return_sequences=True, input_shape=(X_train.shape[1], 1))) # Changed input_shape
model.add(Dropout(0.2))
model.add(GRU(32, activation='tanh', return_sequences=False))
model.add(Dropout(0.2))
model.add(Dense(1, activation='sigmoid'))

# Compile the model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Early stopping
early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)

# Train the model
history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.3, callbacks=[early_stopping], verbose=1)

eval_results = model.evaluate(X_test, y_test, verbose=0)
y_pred = (model.predict(X_test) > 0.5).astype(int).flatten()
roc_score = roc_auc_score(y_test, model.predict(X_test))

# Print performance metrics
print("Test Loss:", eval_results[0])
print("Test Accuracy:", eval_results[1])
print("Classification Report:\n", classification_report(y_test, y_pred))
print("ROC AUC Score:", roc_score)

from tensorflow.keras.layers import Dense, Dropout, GRU, Bidirectional

model = Sequential()
model.add(Bidirectional(GRU(64, activation='tanh', return_sequences=True), input_shape=(X_train.shape[1], 1))) # Changed input_shape to (X_train.shape[1], 1)
model.add(Dropout(0.2))
model.add(Bidirectional(GRU(32, activation='tanh', return_sequences=False)))
model.add(Dropout(0.2))
model.add(Dense(1, activation='sigmoid'))

# Compile the model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Early stopping
early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)

# Train the model
history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2, callbacks=[early_stopping], verbose=1)

eval_results = model.evaluate(X_test, y_test, verbose=0)
y_pred = (model.predict(X_test) > 0.5).astype(int).flatten()
y_prob = model.predict(X_test).flatten()
roc_score = roc_auc_score(y_test, y_prob)

# Print performance metrics
print("Test Loss:", eval_results[0])
print("Test Accuracy:", eval_results[1])
print("Classification Report:\n", classification_report(y_test, y_pred))
print("ROC AUC Score:", roc_score)

from sklearn.neural_network import BernoulliRBM
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression

rbm = BernoulliRBM(random_state=42, n_iter=20, n_components=256)
logistic = LogisticRegression(max_iter=1000, random_state=42)
classifier = Pipeline(steps=[('rbm', rbm), ('logistic', logistic)])

# Train the model
classifier.fit(X_train, y_train)

y_pred = classifier.predict(X_test)
y_prob = classifier.predict_proba(X_test)[:, 1]

# Evaluate the model
roc_score = roc_auc_score(y_test, y_prob)
print("Classification Report:\n", classification_report(y_test, y_pred))
print("ROC AUC Score:", roc_score)